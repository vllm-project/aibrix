# Pod autoscaler works with gpu-optimizer
apiVersion: autoscaling.aibrix.ai/v1alpha1
kind: PodAutoscaler
metadata:
  name: podautoscaler-mock-llama2-7b
  labels:
    app.kubernetes.io/name: aibrix
    app.kubernetes.io/managed-by: kustomize
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: mock-llama2-7b
  minReplicas: 0
  maxReplicas: 10
  targetMetric: "avg_prompt_throughput_toks_per_s" # Ignore if metricsSources is configured
  metricsSources: 
    - endpoint: gpu-optimizer.aibrix-system.svc.cluster.local:8080
      path: /metrics/default/simulator-llama2-7b
      metric: "vllm:deployment_replicas"
  targetValue: "1"
  scalingStrategy: "KPA"