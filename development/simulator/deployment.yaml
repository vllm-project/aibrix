apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-llama3-8b-instruct
  namespace: default
  labels:
    model.aibrix.ai/name: "vllm-llama3-8b-instruct"
    model.aibrix.ai/port: "8010"
    adapter.model.aibrix.ai/enabled: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      model.aibrix.ai/name: "vllm-llama3-8b-instruct"
      adapter.model.aibrix.ai/enabled: "true"
      app: vllm-llama3-8b-instruct
  template:
    metadata:
      labels:
        model.aibrix.ai/name: "vllm-llama3-8b-instruct"
        model.aibrix.ai/port: "8010"
        adapter.model.aibrix.ai/enabled: "true"
        app: vllm-llama3-8b-instruct
    spec:
      serviceAccountName: vllm-llama3-8b-instruct-sa
      containers:
        - name: llm-engine
          image: ghcr.io/llm-d/llm-d-inference-sim:v0.5.0
          imagePullPolicy: IfNotPresent
          args:
            - --model
            - vllm-llama3-8b-instruct
            - --port
            - "8010"
            - --max-loras
            - "2"
            - --lora-modules
            - '{"name": "food-review-1"}'
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 8010
              name: http
              protocol: TCP
          resources:
            requests:
              cpu: 10m
