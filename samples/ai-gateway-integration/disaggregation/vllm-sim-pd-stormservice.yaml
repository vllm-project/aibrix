apiVersion: orchestration.aibrix.ai/v1alpha1
kind: StormService
metadata:
  name: vllm-sim-pd
spec:
  replicas: 1
  updateStrategy:
    type: InPlaceUpdate
  stateful: false
  selector:
    matchLabels:
      app: vllm-sim-pd
  template:
    metadata:
      labels:
        app: vllm-sim-pd
    spec:
      roles:
        - name: prefill
          replicas: 1
          stateful: false
          template:
            metadata:
              labels:
                app: vllm-sim-pd
                role: prefill
                model.aibrix.ai/name: "qwen2-7b"
            spec:
              containers:
                - name: llm-engine
                  image: ghcr.io/llm-d/llm-d-inference-sim:latest
                  imagePullPolicy: IfNotPresent
                  args:
                    - "--v=4"
                    - "--port=8000"
                    - "--model=qwen2-7b"
                    - "--data-parallel-size=1"
                  ports:
                    - containerPort: 8000
                  env:
                    - name: DEPLOYMENT_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.labels['app']
                    - name: POD_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.name
                    - name: POD_NAMESPACE
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.namespace
                    - name: MY_POD_IP
                      valueFrom:
                        fieldRef:
                          fieldPath: status.podIP
        - name: decode
          replicas: 1
          stateful: false
          template:
            metadata:
              labels:
                app: vllm-sim-pd
                role: decode
                model.aibrix.ai/name: "qwen2-7b"
            spec:
              containers:
                - name: routing-sidecar
                  image: ghcr.io/llm-d/llm-d-routing-sidecar:v0.3.1-rc.1
                  imagePullPolicy: IfNotPresent
                  args:
                    - "--v=4"
                    - "--port=8000"
                    - "--vllm-port=8200"
                    - "--connector=nixlv2"
                    - "--secure-proxy=false"
                  ports:
                    - containerPort: 8000
                - name: llm-engine
                  image: ghcr.io/llm-d/llm-d-inference-sim:latest
                  imagePullPolicy: IfNotPresent
                  args:
                    - "--v=4"
                    - "--port=8200"
                    - "--model=qwen2-7b"
                    - "--data-parallel-size=1"
                  ports:
                    - containerPort: 8200
                  env:
                    - name: DEPLOYMENT_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.labels['app']
                    - name: POD_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.name
                    - name: POD_NAMESPACE
                      valueFrom:
                        fieldRef:
                          fieldPath: metadata.namespace
                    - name: MY_POD_IP
                      valueFrom:
                        fieldRef:
                          fieldPath: status.podIP