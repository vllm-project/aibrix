apiVersion: orchestration.aibrix.ai/v1alpha1
kind: StormService
metadata:
  name: vllm-2p2d
  namespace: default
  labels:
    helm.sh/chart: aibrix-regression-test-0.5.0
    app.kubernetes.io/name: aibrix-regression-test
    app.kubernetes.io/instance: vllm-xpyd-rdma
    app.kubernetes.io/version: "0.5.0"
    app.kubernetes.io/managed-by: Helm
    engine: "vllm"
    deployment: "disaggregated"
spec:
  replicas: 1
  updateStrategy:
    type: InPlaceUpdate
  stateful: true
  selector:
    matchLabels:
      app.kubernetes.io/name: aibrix-regression-test
      app.kubernetes.io/instance: vllm-xpyd-rdma
  template:
    metadata:
      labels:
        app.kubernetes.io/name: aibrix-regression-test
        app.kubernetes.io/instance: vllm-xpyd-rdma
    spec:
      roles:
        - name: prefill
          replicas: 2
          stateful: true
          template:
            metadata:
              annotations:
                k8s.volcengine.com/pod-networks: |
                  [
                    {
                      "cniConf":{
                          "name":"rdma"
                      }
                    }
                  ]
              labels:
                model.aibrix.ai/name: qwen3-32b
                model.aibrix.ai/port: "8000"
                model.aibrix.ai/engine: vllm
            spec:
              nodeSelector:
                kubernetes.io/hostname: 192.168.0.7
              containers:
                - name: prefill
                  image: aibrix-container-registry-cn-beijing.cr.volces.com/aibrix/vllm-openai-aibrix-kvcache-nixl:v0.10.2-nixl-0.7.1-ucx-1.19.0
                  command: ["sh", "-c"]
                  args:
                    - |
                      python3 -m vllm.entrypoints.openai.api_server \
                        --host "0.0.0.0" \
                        --port "8000" \
                        --uvicorn-log-level warning \
                        --model /models/Qwen3-32B \
                        --served-model-name qwen3-32b \
                        --disable-log-requests \
                        --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_producer"}' \
                        --tensor-parallel-size=2
                  env:
                    - name: UCX_TLS
                      value: "^gga"
                    - name: GLOO_SOCKET_IFNAME
                      value: "eth0"
                    - name: NCCL_SOCKET_IFNAME
                      value: "eth0"
                    - name: NCCL_IB_DISABLE
                      value: "0"
                    - name: NCCL_IB_GID_INDEX
                      value: "7"
                    - name: NCCL_DEBUG
                      value: "INFO"
                    # VLLM specific env vars (only used when engine.type is vllm)
                    - name: PYTHONHASHSEED
                      value: "1047"
                    - name: VLLM_NIXL_ABORT_REQUEST_TIMEOUT
                      value: "600"
                    - name: VLLM_NIXL_SIDE_CHANNEL_PORT
                      value: "5557"
                    - name: VLLM_NIXL_SIDE_CHANNEL_HOST
                      value: "0.0.0.0"
                    - name: VLLM_SERVER_DEV_MODE
                      value: "1"
                    - name: VLLM_USE_V1
                      value: "1"
                    - name: VLLM_ENABLE_V1_MULTIPROCESSING
                      value: "1"
                    - name: VLLM_WORKER_MULTIPROC_METHOD
                      value: "spawn"
                    - name: UCX_LOG_LEVEL
                      value: info
                    - name: NIXL_LOG_LEVEL
                      value: info
                    - name: VLLM_LOGGING_LEVEL
                      value: info
                  volumeMounts:
                    - name: model-vol
                      mountPath: /models
                      readOnly: true
                    - mountPath: /dev/shm
                      name: shared-mem
                  resources:
                    limits:
                      nvidia.com/gpu: 2
                      vke.volcengine.com/rdma: "1"
                  securityContext:
                    capabilities:
                      add:
                        - IPC_LOCK
              volumes:
                - name: model-vol
                  hostPath:
                    path: /data01/models
                    type: Directory
                - emptyDir:
                    medium: Memory
                  name: shared-mem
        - name: decode
          replicas: 2
          stateful: true
          template:
            metadata:
              annotations:
                k8s.volcengine.com/pod-networks: |
                  [
                    {
                      "cniConf":{
                          "name":"rdma"
                      }
                    }
                  ]
              labels:
                model.aibrix.ai/name: qwen3-32b
                model.aibrix.ai/port: "8000"
                model.aibrix.ai/engine: vllm
            spec:
              nodeSelector:
                kubernetes.io/hostname: 192.168.0.6
              containers:
                - name: decode
                  image: aibrix-container-registry-cn-beijing.cr.volces.com/aibrix/vllm-openai-aibrix-kvcache-nixl:v0.10.2-nixl-0.7.1-ucx-1.19.0
                  command: ["sh", "-c"]
                  args:
                    - |
                      python3 -m vllm.entrypoints.openai.api_server \
                        --host "0.0.0.0" \
                        --port "8000" \
                        --uvicorn-log-level warning \
                        --model /models/Qwen3-32B \
                        --served-model-name qwen3-32b \
                        --disable-log-requests \
                        --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_consumer"}' \
                        --tensor-parallel-size=2
                  env:
                    - name: UCX_TLS
                      value: "^gga"
                    - name: GLOO_SOCKET_IFNAME
                      value: "eth0"
                    - name: NCCL_SOCKET_IFNAME
                      value: "eth0"
                    - name: NCCL_IB_DISABLE
                      value: "0"
                    - name: NCCL_IB_GID_INDEX
                      value: "7"
                    - name: NCCL_DEBUG
                      value: "INFO"
                    - name: PYTHONHASHSEED
                      value: "1047"
                    - name: VLLM_NIXL_ABORT_REQUEST_TIMEOUT
                      value: "600"
                    - name: VLLM_NIXL_SIDE_CHANNEL_PORT
                      value: "5558"
                    - name: VLLM_NIXL_SIDE_CHANNEL_HOST
                      value: "0.0.0.0"
                    - name: VLLM_SERVER_DEV_MODE
                      value: "1"
                    - name: VLLM_USE_V1
                      value: "1"
                    - name: VLLM_ENABLE_V1_MULTIPROCESSING
                      value: "1"
                    - name: VLLM_WORKER_MULTIPROC_METHOD
                      value: "spawn"
                    - name: UCX_LOG_LEVEL
                      value: info
                    - name: NIXL_LOG_LEVEL
                      value: info
                    - name: VLLM_LOGGING_LEVEL
                      value: info
                  volumeMounts:
                    - name: model-vol
                      mountPath: /models
                      readOnly: true
                    - mountPath: /dev/shm
                      name: shared-mem
                  resources:
                    limits:
                      nvidia.com/gpu: 2
                      vke.volcengine.com/rdma: "1"
                  securityContext:
                    capabilities:
                      add:
                        - IPC_LOCK
              volumes:
                - name: model-vol
                  hostPath:
                    path: /data01/models
                    type: Directory
                - emptyDir:
                    medium: Memory
                  name: shared-mem
