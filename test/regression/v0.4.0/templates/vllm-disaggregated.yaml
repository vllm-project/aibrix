{{- if and (eq .Values.engine.type "vllm") (eq .Values.deployment.type "disaggregated") }}
apiVersion: orchestration.aibrix.ai/v1alpha1
kind: StormService
metadata:
  name: {{ include "aibrix-model.fullname" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "aibrix-model.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.deployment.stormReplicas }}
  updateStrategy:
    type: InPlaceUpdate
  stateful: true
  selector:
    matchLabels:
      {{- include "aibrix-model.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "aibrix-model.selectorLabels" . | nindent 8 }}
    spec:
      roles:
        - name: router
          replicas: 1
          template:
            spec:
              containers:
                - name: router
                  image: {{ include "aibrix-model.routerImage" . }}
                  command: [ "sleep", "infinity" ]
        - name: prefill
          replicas: {{ .Values.workers.prefill.replicas }}
          stateful: true
          template:
            metadata:
              {{- if .Values.network.rdma.enabled }}
              annotations:
                {{- include "aibrix-model.rdmaAnnotation" . | nindent 16 }}
              {{- end }}
              labels:
                model.aibrix.ai/name: {{ .Values.model.name }}
                model.aibrix.ai/port: "8000"
                model.aibrix.ai/engine: vllm
            spec:
              {{- if .Values.network.hostNetwork }}
              hostNetwork: true
              {{- end }}
              containers:
                - name: prefill
                  image: {{ include "aibrix-model.engineImage" . }}
                  command: ["sh", "-c"]
                  args:
                    - |
                      python3 -m vllm.entrypoints.openai.api_server \
                        --host "0.0.0.0" \
                        --port "8000" \
                        --uvicorn-log-level warning \
                        --model {{ .Values.model.path }} \
                        --served-model-name {{ .Values.model.name }} \
                        --disable-log-requests \
                        --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
                  env:
                    {{- include "aibrix-model.envVars" . | nindent 20 }}
                    # VLLM specific env vars (only used when engine.type is vllm)
                    - name: PYTHONHASHSEED
                      value: "1047"
                    - name: VLLM_NIXL_SIDE_CHANNEL_PORT
                      value: "5557"
                    - name: VLLM_NIXL_SIDE_CHANNEL_HOST
                      value: "0.0.0.0"
                    - name: VLLM_SERVER_DEV_MODE
                      value: "1"
                    - name: VLLM_USE_V1
                      value: "1"
                    - name: VLLM_ENABLE_V1_MULTIPROCESSING
                      value: "1"
                    - name: VLLM_WORKER_MULTIPROC_METHOD
                      value: "spawn"
                    - name: VLLM_LOGGING_LEVEL
                      value: "DEBUG"
                  volumeMounts:
                    - name: model-vol
                      mountPath: /models
                      readOnly: true
                    {{- if .Values.resources.memory.sharedMemory }}
                    - mountPath: /dev/shm
                      name: shared-mem
                    {{- end }}
                  resources:
                    {{- include "aibrix-model.resources" . | nindent 20 }}
                  securityContext:
                    {{- if .Values.security.privileged }}
                    privileged: true
                    {{- else }}
                    capabilities:
                      add:
                        {{- range .Values.security.capabilities }}
                        - {{ . }}
                        {{- end }}
                    {{- end }}
              volumes:
                - name: model-vol
                  hostPath:
                    path: {{ .Values.volumes.models.hostPath }}
                    type: Directory
                {{- if .Values.resources.memory.sharedMemory }}
                - emptyDir:
                    medium: Memory
                  name: shared-mem
                {{- end }}
        - name: decode
          replicas: {{ .Values.workers.decode.replicas }}
          stateful: true
          template:
            metadata:
              {{- if .Values.network.rdma.enabled }}
              annotations:
                {{- include "aibrix-model.rdmaAnnotation" . | nindent 16 }}
              {{- end }}
              labels:
                model.aibrix.ai/name: {{ .Values.model.name }}
                model.aibrix.ai/port: "8000"
                model.aibrix.ai/engine: vllm
            spec:
              {{- if .Values.network.hostNetwork }}
              hostNetwork: true
              {{- end }}
              containers:
                - name: decode
                  image: {{ include "aibrix-model.engineImage" . }}
                  command: ["sh", "-c"]
                  args:
                    - |
                      python3 -m vllm.entrypoints.openai.api_server \
                        --host "0.0.0.0" \
                        --port "8000" \
                        --uvicorn-log-level warning \
                        --model {{ .Values.model.path }} \
                        --served-model-name {{ .Values.model.name }} \
                        --disable-log-requests \
                        --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
                  env:
                    {{- include "aibrix-model.envVars" . | nindent 20 }}
                    - name: PYTHONHASHSEED
                      value: "1047"
                    - name: VLLM_NIXL_SIDE_CHANNEL_PORT
                      value: "5558"
                    - name: VLLM_NIXL_SIDE_CHANNEL_HOST
                      value: "0.0.0.0"
                    - name: UCX_TLS
                      value: ^gga
                    - name: VLLM_SERVER_DEV_MODE
                      value: "1"
                    - name: VLLM_USE_V1
                      value: "1"
                    - name: VLLM_ENABLE_V1_MULTIPROCESSING
                      value: "1"
                    - name: VLLM_WORKER_MULTIPROC_METHOD
                      value: "spawn"
                    - name: VLLM_LOGGING_LEVEL
                      value: "DEBUG"
                  volumeMounts:
                    - name: model-vol
                      mountPath: /models
                      readOnly: true
                    {{- if .Values.resources.memory.sharedMemory }}
                    - mountPath: /dev/shm
                      name: shared-mem
                    {{- end }}
                  resources:
                    {{- include "aibrix-model.resources" . | nindent 20 }}
                  securityContext:
                    {{- if .Values.security.privileged }}
                    privileged: true
                    {{- else }}
                    capabilities:
                      add:
                        {{- range .Values.security.capabilities }}
                        - {{ . }}
                        {{- end }}
                    {{- end }}
              volumes:
                - name: model-vol
                  hostPath:
                    path: {{ .Values.volumes.models.hostPath }}
                    type: Directory
                {{- if .Values.resources.memory.sharedMemory }}
                - emptyDir:
                    medium: Memory
                  name: shared-mem
                {{- end }}
{{- end }}